Bien sÃ»r Pierre, voici une version **amÃ©liorÃ©e, claire et â€œproâ€** de ton README, **Ã  jour avec ta structure factorisÃ©e et lâ€™usage de Poetry, python-dotenv et modules maison**.
ğŸ‘‰ PrÃªt Ã  copier-coller dans Notion, GitHub, ou ailleursâ€¯!

---

# OC Projet 2 â€” Fashion Trend Intelligence

Ce projet est une preuve de concept de **segmentation automatique de vÃªtements sur images** via un modÃ¨le Hugging Face.
Le code est entiÃ¨rement factorisÃ© et modulaire pour une meilleure maintenance et rÃ©utilisation, selon les standards AI Engineer OpenClassrooms.

---

## ğŸ“ **Structure du projet**

```plaintext
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ interim/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ models/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ references/
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/
â”œâ”€â”€ requirements.txt   # (gÃ©nÃ©rÃ© automatiquement si besoin)
â”œâ”€â”€ pyproject.toml     # (Poetry)
â”œâ”€â”€ .env               # (token API, jamais versionnÃ©)
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ dataset.py
    â”œâ”€â”€ features.py
    â”œâ”€â”€ plots.py
    â”œâ”€â”€ modeling/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ predict.py
    â”‚   â””â”€â”€ train.py
    â””â”€â”€ services/
        â””â”€â”€ __init__.py
```

---

## ğŸš€ **Installation & setup**

### 1. **Cloner le repo & installer Poetry**

```bash
git clone <URL_DU_REPO>
cd <NOM_DU_REPO>
pip install poetry
poetry install
poetry shell
```

---

### 2. **Configuration de la clÃ© API**

- CrÃ©e un fichier `.env` Ã  la racine du projetâ€¯:

  ```dotenv
  API_TOKEN=ton_token_huggingface_ici
  ```

- Le fichier `.env` est **dÃ©jÃ  listÃ© dans `.gitignore`**.

---

### 3. **DÃ©pose tes donnÃ©es**

- Place les images dâ€™exemple dans `data/raw/`.

---

### 4. **Lancer un pipeline dâ€™infÃ©rence dans un notebook**

Dans un nouveau notebook du dossier `notebooks/` :

```python
import sys
sys.path.append("../src")

from dataset import list_images
from features import get_image_dimensions, decode_base64_mask, create_masks
from modeling.predict import segment_images_batch
from plots import display_segmented_images_batch

from dotenv import load_dotenv
import os

load_dotenv("../.env")
api_token = os.getenv("API_TOKEN")

image_dir = "../data/raw/top_influenceurs_2024/IMG/"
max_images = 2
api_url = "https://router.huggingface.co/hf-inference/models/sayeed99/segformer_b3_clothes"

image_paths = list_images(image_dir, max_images)
batch_seg_results = segment_images_batch(image_paths, api_url, api_token)
display_segmented_images_batch(image_paths, batch_seg_results)
```

---

### 5. **(Option) GÃ©nÃ©rer un fichier requirements.txt**

Pour compatibilitÃ© universelle (hors Poetry)â€¯:

```bash
poetry export --format=requirements.txt --output=requirements.txt
```

---

## ğŸ’¡ **Bonnes pratiques**

- **Tous les modules rÃ©utilisables sont factorisÃ©s dans `/src`** pour faciliter la maintenance, le test, et la reproductibilitÃ©.
- **Pas dâ€™API key dans le codeâ€¯:** utilisez le `.env` et `python-dotenv` pour la sÃ©curitÃ©.
- **Le notebook sert uniquement de pipeline, pas dâ€™implÃ©mentation brute.**
- **RedÃ©marrez le kernel Jupyter** aprÃ¨s modification de la structure du projet ou du `.env`.

---

## ğŸ§‘â€ğŸ’» **Contact**

> [pierre.pluton@outlook.fr](mailto:pierre.pluton@outlook.fr) > _Projet rÃ©alisÃ© dans le cadre de la formation OpenClassrooms AI Engineer._

---
